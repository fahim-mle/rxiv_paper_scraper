# Multi-stage Docker build for arXiv Scraper MCP Servers
FROM python:3.12-slim as base

# Install system dependencies
RUN apt-get update && apt-get install -y \
    git \
    curl \
    build-essential \
    pkg-config \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Copy requirements first for better caching
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy source code
COPY . .

# Create application user
RUN useradd --create-home --shell /bin/bash app && \
    chown -R app:app /app

# Switch to application user
USER app

# Create data directories
RUN mkdir -p /app/papers /app/logs/mcp_servers /app/logs/pids

# Production stage
FROM base as production

# Install MCP servers
WORKDIR /app/external_mcp_servers

# Install arXiv MCP server
WORKDIR /app/external_mcp_servers/arxiv-mcp-server
RUN pip install --user -e .

# Install Fetch MCP server
WORKDIR /app/external_mcp_servers/servers/src/fetch
RUN pip install --user -e .

# Back to main directory
WORKDIR /app

# Expose ports for MCP servers
EXPOSE 3001 3004

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:3001/health', timeout=5)" || exit 1

# Start command
CMD ["python", "scripts/start_mcp_servers_docker.py"]